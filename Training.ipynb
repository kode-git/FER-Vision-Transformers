{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMqs6b1onWpO+pSVpaSuSM8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kode-git/FER-Visual-Transformers/blob/main/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "TedQm15ebAc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is used for trains transformers and deep neural networks."
      ],
      "metadata": {
        "id": "WTCi9uLibNun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies and Import Libraries"
      ],
      "metadata": {
        "id": "z270ZRjMbXs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!pip install fvcore\n",
        "!git clone https://github.com/davda54/sam.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX18-RD2bNE2",
        "outputId": "6ba859b1-cbb0-4f21-b39a-6d4d6fedc0c9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2021.10.8)\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20220512.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore) (1.21.6)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 10.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore) (4.64.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore) (0.8.9)\n",
            "Collecting iopath>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20220512-py3-none-any.whl size=61288 sha256=98873706aad03f4fb2b03dfa9dfe39248eddcb9c2ecfa073433fe8068550bf05\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/20/f9/a11a0dd63f4c13678b2a5ec488e48078756505c7777b75b29e\n",
            "Successfully built fvcore\n",
            "Installing collected packages: pyyaml, portalocker, yacs, iopath, fvcore\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed fvcore-0.1.5.post20220512 iopath-0.1.9 portalocker-2.4.0 pyyaml-6.0 yacs-0.1.8\n",
            "fatal: destination path 'sam' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YWeinYu7a7O0"
      },
      "outputs": [],
      "source": [
        "# classic libraries for collections.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# utility library.\n",
        "import random, time, copy\n",
        "\n",
        "# plot libraries.\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "# libraries for image processing.\n",
        "import os, cv2, glob, imageio, sys\n",
        "from PIL import Image\n",
        "# warning library for service warnings.\n",
        "import warnings\n",
        "\n",
        "# machine learning libraries .\n",
        "import timm, torch, torchvision\n",
        "from torchsummary import summary\n",
        "\n",
        "# image dataset loading and transformations.\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "# utility functions for specific uses.\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "\n",
        "# optimizer libraries.\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.optim as optim\n",
        "from sam.sam import SAM\n",
        "\n",
        "# library for basic building blocks.\n",
        "import torch.nn as nn\n",
        "\n",
        "# library for saving and loading checkpoints.\n",
        "import pickle\n",
        "\n",
        "# libraries for metrics and evaluation phase.\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# libraries for flop analysis.\n",
        "from fvcore.nn import FlopCountAnalysis, flop_count_table, flop_count_str\n",
        "\n",
        "# colab library.\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnRVVSa1d6Ze",
        "outputId": "38670851-573b-42b5-b58e-c5ef87d600ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  1.11.0+cu113\n",
            "Torchvision Version:  0.12.0+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load Google Drive environment.\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa53feYLa_qr",
        "outputId": "4bccba83-462e-4013-b517-fd6a3fd7049c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU Configuration"
      ],
      "metadata": {
        "id": "LCQDvI9IddjL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformers are trained using Google Colab Pro GPU: NVIDIA P100."
      ],
      "metadata": {
        "id": "QaNwNAVKdg0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO0H9JgcdgCk",
        "outputId": "4ac65945-33e9-41f0-fd4a-6ad54ae037cb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat May 14 21:26:21 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect if we have a GPU available.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP1OgXp2d1IO",
        "outputId": "d589f290-c10c-4bb6-e184-999dbac55566"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common utilities"
      ],
      "metadata": {
        "id": "3k_z_eI2ccIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mkdir_model(base_dir, name_model, counter):\n",
        "  \"\"\"\n",
        "  Making a directory for the model dump.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    d = \"{}/{}\".format(base_dir,name_model)\n",
        "    os.mkdir(d)\n",
        "  except FileExistsError:\n",
        "    counter += 1\n",
        "    mkdir_model(base_dir, str(name_model) + \"_\" + str(counter), counter)\n",
        "\n",
        "def save_history(history, filename):\n",
        "  \"\"\"\n",
        "  Save the history in the file.\n",
        "  \"\"\"\n",
        "  if os.path.isfile(filename):\n",
        "    os.remove(filename)\n",
        "  file_handler = open(filename + \".pkl\", \"wb\")\n",
        "  pickle.dump(history, file_handler)\n",
        "  file_handler.close()\n",
        "\n",
        "\n",
        "def load_history(filename):\n",
        "  \"\"\"\n",
        "  Load the history from the file.\n",
        "  \"\"\"\n",
        "  file_handler = open(filename + \".pkl\", \"rb\")\n",
        "  output = pickle.load(file_handler)\n",
        "  file_handler.close()\n",
        "  return output\n",
        "\n",
        "\n",
        "def train_model(model, dataloaders, criterion, optimizer,lr_scheduler, num_epochs=25, is_inception=False, \n",
        "                is_loaded = False, load_state_ws=None, history_file_acc=\"history_accuracy\",\n",
        "                history_file_loss=\"history_loss\", n_partial=0, model_folder=\"\", best_acc=0.0 ):\n",
        "    \"\"\"\n",
        "    PyTorch training model with loading support and dump management.\n",
        "    Trains a model in a series of epochs and return the best configuration.\n",
        "    Best configuration is given by the best validation accuracy around epochs.\n",
        "    Training metrics are saved in well formated files.\n",
        "    \"\"\"\n",
        "    \n",
        "    history = {'val' : [], 'train' : []}\n",
        "    loss_history = {'val' : [], 'train' : []}\n",
        "\n",
        "    if is_loaded and load_state_ws != None:\n",
        "      # load the model.\n",
        "      state_dict = torch.load(load_state_ws)\n",
        "      model.load_state_dict(state_dict)\n",
        "      model.eval()\n",
        "      print('Model loaded correctly')\n",
        "\n",
        "    print('Starting Training')\n",
        "    print('-' * 12)\n",
        "\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = best_acc\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_since = time.time()\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "        print('-' * 12)\n",
        "        # Each epoch has a training and validation phase.\n",
        "        for phase in ['train', 'val']:\n",
        "            total = len(dataloaders[phase])\n",
        "            current = 0\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode.\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode.\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            dl = dataloaders[phase]\n",
        "            totalIm=0\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dl:\n",
        "                totalIm+=len(inputs)\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients.\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward.\n",
        "                # track history if only in train.\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss.\n",
        "                      outputs = model(inputs)\n",
        "                      loss = criterion(outputs, labels)\n",
        "\n",
        "                      _, preds = torch.max(outputs, 1)\n",
        "                      def closure():\n",
        "                          outputs = model(inputs)\n",
        "                          _, preds = torch.max(outputs, 1)\n",
        "                          loss = criterion(outputs, labels)\n",
        "                          loss.backward()\n",
        "                          return loss\n",
        "\n",
        "                    # backward + optimize only if in training phase.\n",
        "                      if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        if type(optimizer) != SAM:\n",
        "                          optimizer.step()\n",
        "                        else:\n",
        "                          optimizer.step(closure)\n",
        "\n",
        "                        \n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                epoch_loss = running_loss / totalIm\n",
        "                epoch_acc = running_corrects.double() / totalIm\n",
        "                # status update.\n",
        "                current += 1\n",
        "                sys.stdout.write(\"\\r\" + f\"{epoch + 1}/{num_epochs} - {phase} step : \" + str(current * batch_size) + \"/\" +  str(total * batch_size) + \" - \" + \n",
        "                                 \"{}_accuracy : \".format(phase) + \"{:4f}\".format(epoch_acc) + \" - {}_loss : \".format(phase) + \"{:4f}\".format(epoch_loss))\n",
        "                sys.stdout.flush()\n",
        "            epoch_loss = running_loss / totalIm\n",
        "            epoch_acc = running_corrects.double() / totalIm\n",
        "            print() # avoid result cleaning .\n",
        "            if phase == 'train':\n",
        "              history['train'].append(epoch_acc)\n",
        "              loss_history['train'].append(epoch_loss)\n",
        "\n",
        "            # deep copy the model only in case the accusary is better in evaluation (local optima).\n",
        "            local_optima = False\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                local_optima = True\n",
        "            if phase == 'val':\n",
        "                history['val'].append(epoch_acc)\n",
        "                loss_history['val'].append(epoch_loss)\n",
        "\n",
        "        # Increases the internal counter.\n",
        "        if lr_scheduler:            \n",
        "            lr_scheduler.step()            \n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "        interval_epoch = time.time() - epoch_since \n",
        "        print('\\nEpoch {} complete in. {:.0f}m {:.0f}s {} and with a learning rate of {}'.format(epoch + 1, interval_epoch // 60, interval_epoch % 60, \"with best local accuracy\" if local_optima else \"\",lr))\n",
        "        save_history(loss_history, model_folder + os.path.basename(model_folder) + \"_\" + history_file_loss)\n",
        "        \n",
        "        torch.save(model.state_dict(), model_folder + \"epoch_{}_{}\".format(epoch + 1, os.path.basename(model_folder[:len(model_folder) - 1])))\n",
        "        print(\"-\" * 12)\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val accuracy: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights.\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history['train'], history['val'], best_acc"
      ],
      "metadata": {
        "id": "cpE6-fohcUWF"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Loading"
      ],
      "metadata": {
        "id": "8DalOvLheWX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input and batch size specification.\n",
        "input_size = (224,224)\n",
        "batch_size = 60\n",
        "\n",
        "# dataset directory.\n",
        "data_dir= \"/content/drive/MyDrive/Datasets/VFER/\"\n",
        "\n",
        "# removing possible .ipybn_checkpoints.\n",
        "for fd in glob.glob(\"/content/drive/MyDrive/Datasets/VFER/*\"):\n",
        "  for cl in glob.glob(fd + \"/.*\"):\n",
        "    os.rmdir(cl)\n",
        "\n",
        "# loading training and validation set.\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "# Create training and validation datasets.\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "\n",
        "# Create training and validation dataloaders.\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=8,pin_memory=True) for x in ['train', 'val']}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grsVit1sdUbT",
        "outputId": "29a29244-26d1-46a8-c382-5494629bf1f4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Datasets and Dataloaders...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specify the total number of classes.\n",
        "NUM_CLASSES = 8\n",
        "model_name = 'vit_base_patch16_224'\n",
        "# model_name = 'resnet18'\n",
        "# loading pretrained model.\n",
        "model = timm.create_model(model_name, pretrained=True)"
      ],
      "metadata": {
        "id": "2bw-eR3cern8"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flops analysis.\n",
        "inputs = (torch.randn((1, 3, 224, 224)))\n",
        "model.eval() \n",
        "print('-'*40)\n",
        "\n",
        "# flop data display.\n",
        "flop = FlopCountAnalysis(model, inputs)\n",
        "print(flop_count_table(flop, max_depth=4))\n",
        "print(flop_count_str(flop))\n",
        "print(\"Tot. flops:\", flop.total())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgCr7dMue_6n",
        "outputId": "3cb7ea0d-ca2c-49fb-bd19-7913098ac2a3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "| module                     | #parameters or shape   | #flops     |\n",
            "|:---------------------------|:-----------------------|:-----------|\n",
            "| model                      | 86.568M                | 17.583G    |\n",
            "|  cls_token                 |  (1, 1, 768)           |            |\n",
            "|  pos_embed                 |  (1, 197, 768)         |            |\n",
            "|  patch_embed.proj          |  0.591M                |  0.116G    |\n",
            "|   patch_embed.proj.weight  |   (768, 3, 16, 16)     |            |\n",
            "|   patch_embed.proj.bias    |   (768,)               |            |\n",
            "|  blocks                    |  85.054M               |  17.466G   |\n",
            "|   blocks.0                 |   7.088M               |   1.455G   |\n",
            "|    blocks.0.norm1          |    1.536K              |    0.756M  |\n",
            "|     blocks.0.norm1.weight  |     (768,)             |            |\n",
            "|     blocks.0.norm1.bias    |     (768,)             |            |\n",
            "|    blocks.0.attn           |    2.362M              |    0.524G  |\n",
            "|     blocks.0.attn.qkv      |     1.772M             |     0.349G |\n",
            "|     blocks.0.attn.proj     |     0.591M             |     0.116G |\n",
            "|    blocks.0.norm2          |    1.536K              |    0.756M  |\n",
            "|     blocks.0.norm2.weight  |     (768,)             |            |\n",
            "|     blocks.0.norm2.bias    |     (768,)             |            |\n",
            "|    blocks.0.mlp            |    4.722M              |    0.93G   |\n",
            "|     blocks.0.mlp.fc1       |     2.362M             |     0.465G |\n",
            "|     blocks.0.mlp.fc2       |     2.36M              |     0.465G |\n",
            "|   blocks.1                 |   7.088M               |   1.455G   |\n",
            "|    blocks.1.norm1          |    1.536K              |    0.756M  |\n",
            "|     blocks.1.norm1.weight  |     (768,)             |            |\n",
            "|     blocks.1.norm1.bias    |     (768,)             |            |\n",
            "|    blocks.1.attn           |    2.362M              |    0.524G  |\n",
            "|     blocks.1.attn.qkv      |     1.772M             |     0.349G |\n",
            "|     blocks.1.attn.proj     |     0.591M             |     0.116G |\n",
            "|    blocks.1.norm2          |    1.536K              |    0.756M  |\n",
            "|     blocks.1.norm2.weight  |     (768,)             |            |\n",
            "|     blocks.1.norm2.bias    |     (768,)             |            |\n",
            "|    blocks.1.mlp            |    4.722M              |    0.93G   |\n",
            "|     blocks.1.mlp.fc1       |     2.362M             |     0.465G |\n",
            "|     blocks.1.mlp.fc2       |     2.36M              |     0.465G |\n",
            "|   blocks.2                 |   7.088M               |   1.455G   |\n",
            "|    blocks.2.norm1          |    1.536K              |    0.756M  |\n",
            "|     blocks.2.norm1.weight  |     (768,)             |            |\n",
            "|     blocks.2.norm1.bias    |     (768,)             |            |\n",
            "|    blocks.2.attn           |    2.362M              |    0.524G  |\n",
            "|     blocks.2.attn.qkv      |     1.772M             |     0.349G |\n",
            "|     blocks.2.attn.proj     |     0.591M             |     0.116G |\n",
            "|    blocks.2.norm2          |    1.536K              |    0.756M  |\n",
            "|     blocks.2.norm2.weight  |     (768,)             |            |\n",
            "|     blocks.2.norm2.bias    |     (768,)             |            |\n",
            "|    blocks.2.mlp            |    4.722M              |    0.93G   |\n",
            "|     blocks.2.mlp.fc1       |     2.362M             |     0.465G |\n",
            "|     blocks.2.mlp.fc2       |     2.36M              |     0.465G |\n",
            "|   blocks.3                 |   7.088M               |   1.455G   |\n",
            "|    blocks.3.norm1          |    1.536K              |    0.756M  |\n",
            "|     blocks.3.norm1.weight  |     (768,)             |            |\n",
            "|     blocks.3.norm1.bias    |     (768,)             |            |\n",
            "|    blocks.3.attn           |    2.362M              |    0.524G  |\n",
            "|     blocks.3.attn.qkv      |     1.772M             |     0.349G |\n",
            "|     blocks.3.attn.proj     |     0.591M             |     0.116G |\n",
            "|    blocks.3.norm2          |    1.536K              |    0.756M  |\n",
            "|     blocks.3.norm2.weight  |     (768,)             |            |\n",
            "|     blocks.3.norm2.bias    |     (768,)             |            |\n",
            "|    blocks.3.mlp            |    4.722M              |    0.93G   |\n",
            "|     blocks.3.mlp.fc1       |     2.362M             |     0.465G |\n",
            "|     blocks.3.mlp.fc2       |     2.36M              |     0.465G |\n",
            "|   blocks.4                 |   7.088M               |   1.455G   |\n",
            "|    blocks.4.norm1          |    1.536K              |    0.756M  |\n",
            "|     blocks.4.norm1.weight  |     (768,)             |            |\n",
            "|     blocks.4.norm1.bias    |     (768,)             |            |\n",
            "|    blocks.4.attn           |    2.362M              |    0.524G  |\n",
            "|     blocks.4.attn.qkv      |     1.772M             |     0.349G |\n",
            "|     blocks.4.attn.proj     |     0.591M             |     0.116G |\n",
            "|    blocks.4.norm2          |    1.536K              |    0.756M  |\n",
            "|     blocks.4.norm2.weight  |     (768,)             |            |\n",
            "|     blocks.4.norm2.bias    |     (768,)             |            |\n",
            "|    blocks.4.mlp            |    4.722M              |    0.93G   |\n",
            "|     blocks.4.mlp.fc1       |     2.362M             |     0.465G |\n",
            "|     blocks.4.mlp.fc2       |     2.36M              |     0.465G |\n",
            "|   blocks.5                 |   7.088M               |   1.455G   |\n",
            "|    blocks.5.norm1          |    1.536K              |    0.756M  |\n",
            "|     blocks.5.norm1.weight  |     (768,)             |            |\n",
            "|     blocks.5.norm1.bias    |     (768,)             |            |\n",
            "|    blocks.5.attn           |    2.362M              |    0.524G  |\n",
            "|     blocks.5.attn.qkv      |     1.772M             |     0.349G |\n",
            "|     blocks.5.attn.proj     |     0.591M             |     0.116G |\n",
            "|    blocks.5.norm2          |    1.536K              |    0.756M  |\n",
            "|     blocks.5.norm2.weight  |     (768,)             |            |\n",
            "|     blocks.5.norm2.bias    |     (768,)             |            |\n",
            "|    blocks.5.mlp            |    4.722M              |    0.93G   |\n",
            "|     blocks.5.mlp.fc1       |     2.362M             |     0.465G |\n",
            "|     blocks.5.mlp.fc2       |     2.36M              |     0.465G |\n",
            "|   blocks.6                 |   7.088M               |   1.455G   |\n",
            "|    blocks.6.norm1          |    1.536K              |    0.756M  |\n",
            "|     blocks.6.norm1.weight  |     (768,)             |            |\n",
            "|     blocks.6.norm1.bias    |     (768,)             |            |\n",
            "|    blocks.6.attn           |    2.362M              |    0.524G  |\n",
            "|     blocks.6.attn.qkv      |     1.772M             |     0.349G |\n",
            "|     blocks.6.attn.proj     |     0.591M             |     0.116G |\n",
            "|    blocks.6.norm2          |    1.536K              |    0.756M  |\n",
            "|     blocks.6.norm2.weight  |     (768,)             |            |\n",
            "|     blocks.6.norm2.bias    |     (768,)             |            |\n",
            "|    blocks.6.mlp            |    4.722M              |    0.93G   |\n",
            "|     blocks.6.mlp.fc1       |     2.362M             |     0.465G |\n",
            "|     blocks.6.mlp.fc2       |     2.36M              |     0.465G |\n",
            "|   blocks.7                 |   7.088M               |   1.455G   |\n",
            "|    blocks.7.norm1          |    1.536K              |    0.756M  |\n",
            "|     blocks.7.norm1.weight  |     (768,)             |            |\n",
            "|     blocks.7.norm1.bias    |     (768,)             |            |\n",
            "|    blocks.7.attn           |    2.362M              |    0.524G  |\n",
            "|     blocks.7.attn.qkv      |     1.772M             |     0.349G |\n",
            "|     blocks.7.attn.proj     |     0.591M             |     0.116G |\n",
            "|    blocks.7.norm2          |    1.536K              |    0.756M  |\n",
            "|     blocks.7.norm2.weight  |     (768,)             |            |\n",
            "|     blocks.7.norm2.bias    |     (768,)             |            |\n",
            "|    blocks.7.mlp            |    4.722M              |    0.93G   |\n",
            "|     blocks.7.mlp.fc1       |     2.362M             |     0.465G |\n",
            "|     blocks.7.mlp.fc2       |     2.36M              |     0.465G |\n",
            "|   blocks.8                 |   7.088M               |   1.455G   |\n",
            "|    blocks.8.norm1          |    1.536K              |    0.756M  |\n",
            "|     blocks.8.norm1.weight  |     (768,)             |            |\n",
            "|     blocks.8.norm1.bias    |     (768,)             |            |\n",
            "|    blocks.8.attn           |    2.362M              |    0.524G  |\n",
            "|     blocks.8.attn.qkv      |     1.772M             |     0.349G |\n",
            "|     blocks.8.attn.proj     |     0.591M             |     0.116G |\n",
            "|    blocks.8.norm2          |    1.536K              |    0.756M  |\n",
            "|     blocks.8.norm2.weight  |     (768,)             |            |\n",
            "|     blocks.8.norm2.bias    |     (768,)             |            |\n",
            "|    blocks.8.mlp            |    4.722M              |    0.93G   |\n",
            "|     blocks.8.mlp.fc1       |     2.362M             |     0.465G |\n",
            "|     blocks.8.mlp.fc2       |     2.36M              |     0.465G |\n",
            "|   blocks.9                 |   7.088M               |   1.455G   |\n",
            "|    blocks.9.norm1          |    1.536K              |    0.756M  |\n",
            "|     blocks.9.norm1.weight  |     (768,)             |            |\n",
            "|     blocks.9.norm1.bias    |     (768,)             |            |\n",
            "|    blocks.9.attn           |    2.362M              |    0.524G  |\n",
            "|     blocks.9.attn.qkv      |     1.772M             |     0.349G |\n",
            "|     blocks.9.attn.proj     |     0.591M             |     0.116G |\n",
            "|    blocks.9.norm2          |    1.536K              |    0.756M  |\n",
            "|     blocks.9.norm2.weight  |     (768,)             |            |\n",
            "|     blocks.9.norm2.bias    |     (768,)             |            |\n",
            "|    blocks.9.mlp            |    4.722M              |    0.93G   |\n",
            "|     blocks.9.mlp.fc1       |     2.362M             |     0.465G |\n",
            "|     blocks.9.mlp.fc2       |     2.36M              |     0.465G |\n",
            "|   blocks.10                |   7.088M               |   1.455G   |\n",
            "|    blocks.10.norm1         |    1.536K              |    0.756M  |\n",
            "|     blocks.10.norm1.weight |     (768,)             |            |\n",
            "|     blocks.10.norm1.bias   |     (768,)             |            |\n",
            "|    blocks.10.attn          |    2.362M              |    0.524G  |\n",
            "|     blocks.10.attn.qkv     |     1.772M             |     0.349G |\n",
            "|     blocks.10.attn.proj    |     0.591M             |     0.116G |\n",
            "|    blocks.10.norm2         |    1.536K              |    0.756M  |\n",
            "|     blocks.10.norm2.weight |     (768,)             |            |\n",
            "|     blocks.10.norm2.bias   |     (768,)             |            |\n",
            "|    blocks.10.mlp           |    4.722M              |    0.93G   |\n",
            "|     blocks.10.mlp.fc1      |     2.362M             |     0.465G |\n",
            "|     blocks.10.mlp.fc2      |     2.36M              |     0.465G |\n",
            "|   blocks.11                |   7.088M               |   1.455G   |\n",
            "|    blocks.11.norm1         |    1.536K              |    0.756M  |\n",
            "|     blocks.11.norm1.weight |     (768,)             |            |\n",
            "|     blocks.11.norm1.bias   |     (768,)             |            |\n",
            "|    blocks.11.attn          |    2.362M              |    0.524G  |\n",
            "|     blocks.11.attn.qkv     |     1.772M             |     0.349G |\n",
            "|     blocks.11.attn.proj    |     0.591M             |     0.116G |\n",
            "|    blocks.11.norm2         |    1.536K              |    0.756M  |\n",
            "|     blocks.11.norm2.weight |     (768,)             |            |\n",
            "|     blocks.11.norm2.bias   |     (768,)             |            |\n",
            "|    blocks.11.mlp           |    4.722M              |    0.93G   |\n",
            "|     blocks.11.mlp.fc1      |     2.362M             |     0.465G |\n",
            "|     blocks.11.mlp.fc2      |     2.36M              |     0.465G |\n",
            "|  norm                      |  1.536K                |  0.756M    |\n",
            "|   norm.weight              |   (768,)               |            |\n",
            "|   norm.bias                |   (768,)               |            |\n",
            "|  head                      |  0.769M                |  0.768M    |\n",
            "|   head.weight              |   (1000, 768)          |            |\n",
            "|   head.bias                |   (1000,)              |            |\n",
            "N/A indicates a possibly missing statistic due to how the module was called. Missing values are still included in the parent's total.\n",
            "VisionTransformer(\n",
            "  #params: 86.57M, #flops: 17.58G\n",
            "  (patch_embed): PatchEmbed(\n",
            "    #params: 0.59M, #flops: 0.12G\n",
            "    (proj): Conv2d(\n",
            "      3, 768, kernel_size=(16, 16), stride=(16, 16)\n",
            "      #params: 0.59M, #flops: 0.12G\n",
            "    )\n",
            "    (norm): Identity(#params: 0, #flops: N/A)\n",
            "  )\n",
            "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "  (blocks): Sequential(\n",
            "    #params: 85.05M, #flops: 17.47G\n",
            "    (0): Block(\n",
            "      #params: 7.09M, #flops: 1.46G\n",
            "      (norm1): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        #params: 2.36M, #flops: 0.52G\n",
            "        (qkv): Linear(\n",
            "          in_features=768, out_features=2304, bias=True\n",
            "          #params: 1.77M, #flops: 0.35G\n",
            "        )\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(\n",
            "          in_features=768, out_features=768, bias=True\n",
            "          #params: 0.59M, #flops: 0.12G\n",
            "        )\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity(#params: 0, #flops: N/A)\n",
            "      (norm2): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (mlp): Mlp(\n",
            "        #params: 4.72M, #flops: 0.93G\n",
            "        (fc1): Linear(\n",
            "          in_features=768, out_features=3072, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (act): GELU()\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (fc2): Linear(\n",
            "          in_features=3072, out_features=768, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (1): Block(\n",
            "      #params: 7.09M, #flops: 1.46G\n",
            "      (norm1): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        #params: 2.36M, #flops: 0.52G\n",
            "        (qkv): Linear(\n",
            "          in_features=768, out_features=2304, bias=True\n",
            "          #params: 1.77M, #flops: 0.35G\n",
            "        )\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(\n",
            "          in_features=768, out_features=768, bias=True\n",
            "          #params: 0.59M, #flops: 0.12G\n",
            "        )\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity(#params: 0, #flops: N/A)\n",
            "      (norm2): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (mlp): Mlp(\n",
            "        #params: 4.72M, #flops: 0.93G\n",
            "        (fc1): Linear(\n",
            "          in_features=768, out_features=3072, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (act): GELU()\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (fc2): Linear(\n",
            "          in_features=3072, out_features=768, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (2): Block(\n",
            "      #params: 7.09M, #flops: 1.46G\n",
            "      (norm1): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        #params: 2.36M, #flops: 0.52G\n",
            "        (qkv): Linear(\n",
            "          in_features=768, out_features=2304, bias=True\n",
            "          #params: 1.77M, #flops: 0.35G\n",
            "        )\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(\n",
            "          in_features=768, out_features=768, bias=True\n",
            "          #params: 0.59M, #flops: 0.12G\n",
            "        )\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity(#params: 0, #flops: N/A)\n",
            "      (norm2): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (mlp): Mlp(\n",
            "        #params: 4.72M, #flops: 0.93G\n",
            "        (fc1): Linear(\n",
            "          in_features=768, out_features=3072, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (act): GELU()\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (fc2): Linear(\n",
            "          in_features=3072, out_features=768, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (3): Block(\n",
            "      #params: 7.09M, #flops: 1.46G\n",
            "      (norm1): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        #params: 2.36M, #flops: 0.52G\n",
            "        (qkv): Linear(\n",
            "          in_features=768, out_features=2304, bias=True\n",
            "          #params: 1.77M, #flops: 0.35G\n",
            "        )\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(\n",
            "          in_features=768, out_features=768, bias=True\n",
            "          #params: 0.59M, #flops: 0.12G\n",
            "        )\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity(#params: 0, #flops: N/A)\n",
            "      (norm2): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (mlp): Mlp(\n",
            "        #params: 4.72M, #flops: 0.93G\n",
            "        (fc1): Linear(\n",
            "          in_features=768, out_features=3072, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (act): GELU()\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (fc2): Linear(\n",
            "          in_features=3072, out_features=768, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (4): Block(\n",
            "      #params: 7.09M, #flops: 1.46G\n",
            "      (norm1): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        #params: 2.36M, #flops: 0.52G\n",
            "        (qkv): Linear(\n",
            "          in_features=768, out_features=2304, bias=True\n",
            "          #params: 1.77M, #flops: 0.35G\n",
            "        )\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(\n",
            "          in_features=768, out_features=768, bias=True\n",
            "          #params: 0.59M, #flops: 0.12G\n",
            "        )\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity(#params: 0, #flops: N/A)\n",
            "      (norm2): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (mlp): Mlp(\n",
            "        #params: 4.72M, #flops: 0.93G\n",
            "        (fc1): Linear(\n",
            "          in_features=768, out_features=3072, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (act): GELU()\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (fc2): Linear(\n",
            "          in_features=3072, out_features=768, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (5): Block(\n",
            "      #params: 7.09M, #flops: 1.46G\n",
            "      (norm1): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        #params: 2.36M, #flops: 0.52G\n",
            "        (qkv): Linear(\n",
            "          in_features=768, out_features=2304, bias=True\n",
            "          #params: 1.77M, #flops: 0.35G\n",
            "        )\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(\n",
            "          in_features=768, out_features=768, bias=True\n",
            "          #params: 0.59M, #flops: 0.12G\n",
            "        )\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity(#params: 0, #flops: N/A)\n",
            "      (norm2): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (mlp): Mlp(\n",
            "        #params: 4.72M, #flops: 0.93G\n",
            "        (fc1): Linear(\n",
            "          in_features=768, out_features=3072, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (act): GELU()\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (fc2): Linear(\n",
            "          in_features=3072, out_features=768, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (6): Block(\n",
            "      #params: 7.09M, #flops: 1.46G\n",
            "      (norm1): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        #params: 2.36M, #flops: 0.52G\n",
            "        (qkv): Linear(\n",
            "          in_features=768, out_features=2304, bias=True\n",
            "          #params: 1.77M, #flops: 0.35G\n",
            "        )\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(\n",
            "          in_features=768, out_features=768, bias=True\n",
            "          #params: 0.59M, #flops: 0.12G\n",
            "        )\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity(#params: 0, #flops: N/A)\n",
            "      (norm2): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (mlp): Mlp(\n",
            "        #params: 4.72M, #flops: 0.93G\n",
            "        (fc1): Linear(\n",
            "          in_features=768, out_features=3072, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (act): GELU()\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (fc2): Linear(\n",
            "          in_features=3072, out_features=768, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (7): Block(\n",
            "      #params: 7.09M, #flops: 1.46G\n",
            "      (norm1): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        #params: 2.36M, #flops: 0.52G\n",
            "        (qkv): Linear(\n",
            "          in_features=768, out_features=2304, bias=True\n",
            "          #params: 1.77M, #flops: 0.35G\n",
            "        )\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(\n",
            "          in_features=768, out_features=768, bias=True\n",
            "          #params: 0.59M, #flops: 0.12G\n",
            "        )\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity(#params: 0, #flops: N/A)\n",
            "      (norm2): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (mlp): Mlp(\n",
            "        #params: 4.72M, #flops: 0.93G\n",
            "        (fc1): Linear(\n",
            "          in_features=768, out_features=3072, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (act): GELU()\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (fc2): Linear(\n",
            "          in_features=3072, out_features=768, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (8): Block(\n",
            "      #params: 7.09M, #flops: 1.46G\n",
            "      (norm1): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        #params: 2.36M, #flops: 0.52G\n",
            "        (qkv): Linear(\n",
            "          in_features=768, out_features=2304, bias=True\n",
            "          #params: 1.77M, #flops: 0.35G\n",
            "        )\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(\n",
            "          in_features=768, out_features=768, bias=True\n",
            "          #params: 0.59M, #flops: 0.12G\n",
            "        )\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity(#params: 0, #flops: N/A)\n",
            "      (norm2): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (mlp): Mlp(\n",
            "        #params: 4.72M, #flops: 0.93G\n",
            "        (fc1): Linear(\n",
            "          in_features=768, out_features=3072, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (act): GELU()\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (fc2): Linear(\n",
            "          in_features=3072, out_features=768, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (9): Block(\n",
            "      #params: 7.09M, #flops: 1.46G\n",
            "      (norm1): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        #params: 2.36M, #flops: 0.52G\n",
            "        (qkv): Linear(\n",
            "          in_features=768, out_features=2304, bias=True\n",
            "          #params: 1.77M, #flops: 0.35G\n",
            "        )\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(\n",
            "          in_features=768, out_features=768, bias=True\n",
            "          #params: 0.59M, #flops: 0.12G\n",
            "        )\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity(#params: 0, #flops: N/A)\n",
            "      (norm2): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (mlp): Mlp(\n",
            "        #params: 4.72M, #flops: 0.93G\n",
            "        (fc1): Linear(\n",
            "          in_features=768, out_features=3072, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (act): GELU()\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (fc2): Linear(\n",
            "          in_features=3072, out_features=768, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (10): Block(\n",
            "      #params: 7.09M, #flops: 1.46G\n",
            "      (norm1): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        #params: 2.36M, #flops: 0.52G\n",
            "        (qkv): Linear(\n",
            "          in_features=768, out_features=2304, bias=True\n",
            "          #params: 1.77M, #flops: 0.35G\n",
            "        )\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(\n",
            "          in_features=768, out_features=768, bias=True\n",
            "          #params: 0.59M, #flops: 0.12G\n",
            "        )\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity(#params: 0, #flops: N/A)\n",
            "      (norm2): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (mlp): Mlp(\n",
            "        #params: 4.72M, #flops: 0.93G\n",
            "        (fc1): Linear(\n",
            "          in_features=768, out_features=3072, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (act): GELU()\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (fc2): Linear(\n",
            "          in_features=3072, out_features=768, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (11): Block(\n",
            "      #params: 7.09M, #flops: 1.46G\n",
            "      (norm1): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        #params: 2.36M, #flops: 0.52G\n",
            "        (qkv): Linear(\n",
            "          in_features=768, out_features=2304, bias=True\n",
            "          #params: 1.77M, #flops: 0.35G\n",
            "        )\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(\n",
            "          in_features=768, out_features=768, bias=True\n",
            "          #params: 0.59M, #flops: 0.12G\n",
            "        )\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity(#params: 0, #flops: N/A)\n",
            "      (norm2): LayerNorm(\n",
            "        (768,), eps=1e-06, elementwise_affine=True\n",
            "        #params: 1.54K, #flops: 0.76M\n",
            "      )\n",
            "      (mlp): Mlp(\n",
            "        #params: 4.72M, #flops: 0.93G\n",
            "        (fc1): Linear(\n",
            "          in_features=768, out_features=3072, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (act): GELU()\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (fc2): Linear(\n",
            "          in_features=3072, out_features=768, bias=True\n",
            "          #params: 2.36M, #flops: 0.46G\n",
            "        )\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm(\n",
            "    (768,), eps=1e-06, elementwise_affine=True\n",
            "    #params: 1.54K, #flops: 0.76M\n",
            "  )\n",
            "  (pre_logits): Identity(#params: 0, #flops: N/A)\n",
            "  (head): Linear(\n",
            "    in_features=768, out_features=1000, bias=True\n",
            "    #params: 0.77M, #flops: 0.77M\n",
            "  )\n",
            ")\n",
            "Tot. flops: 17582740224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adapting head for 8 classes classify (fine-tuning).\n",
        "\n",
        "if model_name == 'resnet18':\n",
        "  model.fc = nn.Linear(512, NUM_CLASSES)\n",
        "else: \n",
        "  model.head = nn.Linear(768, NUM_CLASSES)\n",
        "  \n",
        "# display modified model.\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTVMuJLafWtW",
        "outputId": "f2d33d29-8b10-49e3-ec13-9fa050dbe052"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionTransformer(\n",
              "  (patch_embed): PatchEmbed(\n",
              "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "    (norm): Identity()\n",
              "  )\n",
              "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "  (blocks): Sequential(\n",
              "    (0): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU()\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (1): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU()\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (2): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU()\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (3): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU()\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (4): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU()\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (5): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU()\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (6): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU()\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (7): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU()\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (8): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU()\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (9): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU()\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (10): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU()\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (11): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU()\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  (pre_logits): Identity()\n",
              "  (head): Linear(in_features=768, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_set = input('Digit 0 for SGD or other values for SAM: ')\n",
        "if optimizer_set == str(0):\n",
        "  optimizer_set = \"SGD\"\n",
        "else:\n",
        "  optimizer_set = \"SAM\"\n",
        "print('Chosen {} for the model training.'.format(optimizer_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqQHhSRjgwKv",
        "outputId": "f29a4b7c-7a86-4f82-dc2e-082819cf7c1f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Digit 0 for SGD or other values for SAM: 0\n",
            "Chosen SGD for the model training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect if we have a GPU available.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "# Send the model to GPU\n",
        "model = model.to(device)\n",
        "feature_extract=False\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model.parameters()\n",
        "print(\"Params to learn:\")\n",
        "\n",
        "for name,param in model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "          print(\"\\t\",name)\n",
        "\n",
        "print('-'*40)\n",
        "lr_in = 0.001\n",
        "momentum_in = 0.9\n",
        "if optimizer_set == \"SGD\":\n",
        "  # stochasic gradient descent.\n",
        "  optimizer_ft = optim.SGD(params_to_update, lr=lr_in, momentum=momentum_in)\n",
        "else:\n",
        "  # shapeness-aware minimizer.\n",
        "  optimizer_base = optim.SGD # define an optimizer for the sharpness-aware update.\n",
        "  optimizer_ft = SAM(params_to_update, optimizer_base, lr=lr_in, momentum=momentum_in)\n",
        "\n",
        "print(optimizer_ft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RB46k_5fqKF",
        "outputId": "3c8cb790-b377-408c-cf97-0f5aeb188392"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Params to learn:\n",
            "\t cls_token\n",
            "\t pos_embed\n",
            "\t patch_embed.proj.weight\n",
            "\t patch_embed.proj.bias\n",
            "\t blocks.0.norm1.weight\n",
            "\t blocks.0.norm1.bias\n",
            "\t blocks.0.attn.qkv.weight\n",
            "\t blocks.0.attn.qkv.bias\n",
            "\t blocks.0.attn.proj.weight\n",
            "\t blocks.0.attn.proj.bias\n",
            "\t blocks.0.norm2.weight\n",
            "\t blocks.0.norm2.bias\n",
            "\t blocks.0.mlp.fc1.weight\n",
            "\t blocks.0.mlp.fc1.bias\n",
            "\t blocks.0.mlp.fc2.weight\n",
            "\t blocks.0.mlp.fc2.bias\n",
            "\t blocks.1.norm1.weight\n",
            "\t blocks.1.norm1.bias\n",
            "\t blocks.1.attn.qkv.weight\n",
            "\t blocks.1.attn.qkv.bias\n",
            "\t blocks.1.attn.proj.weight\n",
            "\t blocks.1.attn.proj.bias\n",
            "\t blocks.1.norm2.weight\n",
            "\t blocks.1.norm2.bias\n",
            "\t blocks.1.mlp.fc1.weight\n",
            "\t blocks.1.mlp.fc1.bias\n",
            "\t blocks.1.mlp.fc2.weight\n",
            "\t blocks.1.mlp.fc2.bias\n",
            "\t blocks.2.norm1.weight\n",
            "\t blocks.2.norm1.bias\n",
            "\t blocks.2.attn.qkv.weight\n",
            "\t blocks.2.attn.qkv.bias\n",
            "\t blocks.2.attn.proj.weight\n",
            "\t blocks.2.attn.proj.bias\n",
            "\t blocks.2.norm2.weight\n",
            "\t blocks.2.norm2.bias\n",
            "\t blocks.2.mlp.fc1.weight\n",
            "\t blocks.2.mlp.fc1.bias\n",
            "\t blocks.2.mlp.fc2.weight\n",
            "\t blocks.2.mlp.fc2.bias\n",
            "\t blocks.3.norm1.weight\n",
            "\t blocks.3.norm1.bias\n",
            "\t blocks.3.attn.qkv.weight\n",
            "\t blocks.3.attn.qkv.bias\n",
            "\t blocks.3.attn.proj.weight\n",
            "\t blocks.3.attn.proj.bias\n",
            "\t blocks.3.norm2.weight\n",
            "\t blocks.3.norm2.bias\n",
            "\t blocks.3.mlp.fc1.weight\n",
            "\t blocks.3.mlp.fc1.bias\n",
            "\t blocks.3.mlp.fc2.weight\n",
            "\t blocks.3.mlp.fc2.bias\n",
            "\t blocks.4.norm1.weight\n",
            "\t blocks.4.norm1.bias\n",
            "\t blocks.4.attn.qkv.weight\n",
            "\t blocks.4.attn.qkv.bias\n",
            "\t blocks.4.attn.proj.weight\n",
            "\t blocks.4.attn.proj.bias\n",
            "\t blocks.4.norm2.weight\n",
            "\t blocks.4.norm2.bias\n",
            "\t blocks.4.mlp.fc1.weight\n",
            "\t blocks.4.mlp.fc1.bias\n",
            "\t blocks.4.mlp.fc2.weight\n",
            "\t blocks.4.mlp.fc2.bias\n",
            "\t blocks.5.norm1.weight\n",
            "\t blocks.5.norm1.bias\n",
            "\t blocks.5.attn.qkv.weight\n",
            "\t blocks.5.attn.qkv.bias\n",
            "\t blocks.5.attn.proj.weight\n",
            "\t blocks.5.attn.proj.bias\n",
            "\t blocks.5.norm2.weight\n",
            "\t blocks.5.norm2.bias\n",
            "\t blocks.5.mlp.fc1.weight\n",
            "\t blocks.5.mlp.fc1.bias\n",
            "\t blocks.5.mlp.fc2.weight\n",
            "\t blocks.5.mlp.fc2.bias\n",
            "\t blocks.6.norm1.weight\n",
            "\t blocks.6.norm1.bias\n",
            "\t blocks.6.attn.qkv.weight\n",
            "\t blocks.6.attn.qkv.bias\n",
            "\t blocks.6.attn.proj.weight\n",
            "\t blocks.6.attn.proj.bias\n",
            "\t blocks.6.norm2.weight\n",
            "\t blocks.6.norm2.bias\n",
            "\t blocks.6.mlp.fc1.weight\n",
            "\t blocks.6.mlp.fc1.bias\n",
            "\t blocks.6.mlp.fc2.weight\n",
            "\t blocks.6.mlp.fc2.bias\n",
            "\t blocks.7.norm1.weight\n",
            "\t blocks.7.norm1.bias\n",
            "\t blocks.7.attn.qkv.weight\n",
            "\t blocks.7.attn.qkv.bias\n",
            "\t blocks.7.attn.proj.weight\n",
            "\t blocks.7.attn.proj.bias\n",
            "\t blocks.7.norm2.weight\n",
            "\t blocks.7.norm2.bias\n",
            "\t blocks.7.mlp.fc1.weight\n",
            "\t blocks.7.mlp.fc1.bias\n",
            "\t blocks.7.mlp.fc2.weight\n",
            "\t blocks.7.mlp.fc2.bias\n",
            "\t blocks.8.norm1.weight\n",
            "\t blocks.8.norm1.bias\n",
            "\t blocks.8.attn.qkv.weight\n",
            "\t blocks.8.attn.qkv.bias\n",
            "\t blocks.8.attn.proj.weight\n",
            "\t blocks.8.attn.proj.bias\n",
            "\t blocks.8.norm2.weight\n",
            "\t blocks.8.norm2.bias\n",
            "\t blocks.8.mlp.fc1.weight\n",
            "\t blocks.8.mlp.fc1.bias\n",
            "\t blocks.8.mlp.fc2.weight\n",
            "\t blocks.8.mlp.fc2.bias\n",
            "\t blocks.9.norm1.weight\n",
            "\t blocks.9.norm1.bias\n",
            "\t blocks.9.attn.qkv.weight\n",
            "\t blocks.9.attn.qkv.bias\n",
            "\t blocks.9.attn.proj.weight\n",
            "\t blocks.9.attn.proj.bias\n",
            "\t blocks.9.norm2.weight\n",
            "\t blocks.9.norm2.bias\n",
            "\t blocks.9.mlp.fc1.weight\n",
            "\t blocks.9.mlp.fc1.bias\n",
            "\t blocks.9.mlp.fc2.weight\n",
            "\t blocks.9.mlp.fc2.bias\n",
            "\t blocks.10.norm1.weight\n",
            "\t blocks.10.norm1.bias\n",
            "\t blocks.10.attn.qkv.weight\n",
            "\t blocks.10.attn.qkv.bias\n",
            "\t blocks.10.attn.proj.weight\n",
            "\t blocks.10.attn.proj.bias\n",
            "\t blocks.10.norm2.weight\n",
            "\t blocks.10.norm2.bias\n",
            "\t blocks.10.mlp.fc1.weight\n",
            "\t blocks.10.mlp.fc1.bias\n",
            "\t blocks.10.mlp.fc2.weight\n",
            "\t blocks.10.mlp.fc2.bias\n",
            "\t blocks.11.norm1.weight\n",
            "\t blocks.11.norm1.bias\n",
            "\t blocks.11.attn.qkv.weight\n",
            "\t blocks.11.attn.qkv.bias\n",
            "\t blocks.11.attn.proj.weight\n",
            "\t blocks.11.attn.proj.bias\n",
            "\t blocks.11.norm2.weight\n",
            "\t blocks.11.norm2.bias\n",
            "\t blocks.11.mlp.fc1.weight\n",
            "\t blocks.11.mlp.fc1.bias\n",
            "\t blocks.11.mlp.fc2.weight\n",
            "\t blocks.11.mlp.fc2.bias\n",
            "\t norm.weight\n",
            "\t norm.bias\n",
            "\t head.weight\n",
            "\t head.bias\n",
            "----------------------------------------\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start Training"
      ],
      "metadata": {
        "id": "7RJIMBC4joKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "num_epochs = input('Digits the initial number of epochs, invalid values are equals to 10 epochs: ')\n",
        "try:\n",
        "  int(num_epochs)\n",
        "except ValueError:\n",
        "  print('Default number of 10 epochs selected.')\n",
        "  num_epochs = 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSQCVvBqh3OG",
        "outputId": "bea75a20-f23a-45b1-82b7-ada4dc560ee8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Digits the initial number of epochs, invalid values are equals to 10 epochs: 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model general info.\n",
        "name_model = \"vfer_small_5\"\n",
        "base_dir = \"/content/drive/MyDrive/Models/\"\n",
        "\n",
        "# model files for saving history and model data.\n",
        "model_folder = base_dir + name_model + \"/\"\n",
        "model_file = model_folder + name_model + \".pth\"\n",
        "train_history = model_folder + name_model + \"_\" + \"history_train\"\n",
        "val_history = model_folder + name_model + \"_\" + \"history_val\"\n",
        "\n",
        "\n",
        "# Learning Rate schedule: decays the learning rate by a factor of `gamma` .\n",
        "# every `step_size` epochs.\n",
        "scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "z1S7T5RYjR-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir_model(base_dir, name_model, 0)\n",
        "# Train and evaluate\n",
        "model, train_hist, val_hist, best_acc = train_model(model, dataloaders_dict, criterion, optimizer_ft,scheduler, num_epochs=num_epochs, \n",
        "                                          is_inception=False)\n",
        "#Saving the updated model for the inference phase\n",
        "torch.save(model.state_dict(), model_file)\n",
        "\n",
        "# Save histories data\n",
        "save_history(train_hist, train_history)\n",
        "save_history(val_hist, val_history)"
      ],
      "metadata": {
        "id": "4R6KugZ2jUzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Num epochs for this snippet\n",
        "num_epochs = 10\n",
        "\n",
        "# model general info\n",
        "name_model = \"vfer_small_15\"\n",
        "base_dir = \"/content/drive/MyDrive/Models/\"\n",
        "mkdir_model(base_dir, name_model, 0)\n",
        "\n",
        "# model files for saving history and model data\n",
        "model_folder = base_dir + name_model + \"/\"\n",
        "model_file = model_folder + name_model + \".pth\"\n",
        "train_history = model_folder + name_model + \"_\" + \"history_train\"\n",
        "val_history = model_folder + name_model + \"_\" + \"history_val\"\n",
        "\n",
        "# changing starting lr\n",
        "lr_in = 0.001\n",
        "optimizer_ft = optim.SGD(model.parameters(), lr=lr_in, momentum=momentum_in)\n",
        "scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
        "\n",
        "# Train and evaluate\n",
        "model, train_hist, val_hist, best_acc = train_model(model, dataloaders_dict, criterion, optimizer_ft,scheduler, num_epochs=num_epochs, \n",
        "                                          is_inception=False, is_loaded=True, model_folder= model_folder, best_acc=best_acc,\n",
        "                                          load_state_ws=\"/content/drive/MyDrive/Models/vfer_small_5/vfer_small_5.pth\")\n",
        "\n",
        "\n",
        "#Saving the updated model for the inference phase\n",
        "torch.save(model.state_dict(), model_file)\n",
        "\n",
        "# Save histories data\n",
        "save_history(train_hist, train_history)\n",
        "save_history(val_hist, val_history)"
      ],
      "metadata": {
        "id": "OcV_0RB6jYJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model general info\n",
        "name_model = \"vfer_sam_25\"\n",
        "base_dir = \"/content/drive/MyDrive/Models/\"\n",
        "mkdir_model(base_dir, name_model, 0)\n",
        "\n",
        "# model files for saving history and model data\n",
        "model_folder = base_dir + name_model + \"/\"\n",
        "model_file = model_folder + name_model + \".pth\"\n",
        "train_history = model_folder + name_model + \"_\" + \"history_train\"\n",
        "val_history = model_folder + name_model + \"_\" + \"history_val\"\n",
        "\n",
        "# updating num_epochs\n",
        "num_epochs = 5\n",
        "# changing starting lr\n",
        "lr_in = 0.001\n",
        "optimizer_ft = optim.SGD(model.parameters(), lr=lr_in, momentum=momentum_in)\n",
        "scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
        "\n",
        "# Train and evaluate\n",
        "model, train_hist, val_hist, best_acc = train_model(model, dataloaders_dict, criterion, optimizer_ft,scheduler, num_epochs=num_epochs, \n",
        "                                          is_inception=False, is_loaded=True, model_folder= model_folder,\n",
        "                                          load_state_ws=\"/content/drive/MyDrive/Models/vfer_sam_10/vfer_sam_10.pth\", best_acc=best_acc )\n",
        "\n",
        "\n",
        "#Saving the updated model for the inference phase\n",
        "torch.save(model.state_dict(), model_file)\n",
        "\n",
        "# Save histories data\n",
        "save_history(train_hist, train_history)\n",
        "save_history(val_hist, val_history)"
      ],
      "metadata": {
        "id": "Wgtdw0D8jeCK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}